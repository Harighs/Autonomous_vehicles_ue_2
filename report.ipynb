{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3D object detection",
   "id": "e22bd0d790b01abd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The chosen model and justification for its selection.\n",
    "  -  We have chosen the https://github.com/maudzung/SFA3D (SFA3D) for the 3d object detection task.\n",
    "  - Paper focuses on 3D object detection using LiDAR point clouds. \n",
    "  - From the paper we could see that this method does not uses Non-Max Suppression which is computationally expensive, further focusing on real-time 3d object detection applications like in our case, vehicle detection tasks.\n",
    "  - The model's inference is simple in terms of input data like a bird's-eye view (BEV) map encoded by height, intensity, and other features extracted from the raw LiDAR data.\n",
    "  \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "750f3ce569d4f08c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model configuration.\n",
    "- Feature Pyramid Network (FPN) with ResNet: The model uses FPN built on a ResNet backbone to process the LiDAR data. This combination particularly helps in detecting objects across various scales and sizes by utilizing a hierarchical feature pyramid.\n",
    "- No Non-Max Suppression (NMS): Unlike typical detection frameworks that use NMS to filter out overlapping boxes, SFA3D skips this step to speed up the detection process.\n",
    "- Model takes BEV map and returns bounding box information in 3d space such as class_scores, x, y, z, length, width, height and yaw.\n",
    "- The returned model predictions are in BEV co-ordinates and further we scale it to lidar co-ordinates.\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ],
   "id": "ed2e42fc85c19684"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Overview of Bird's Eye View (BEV) calculation.\n",
    "- Model uses a bird's-eye view (BEV) map to represent the LiDAR point cloud data. The BEV map is a 2D representation of the 3D point cloud data from a top-down perspective.    \n",
    "- The BEV map is created by discretizing the 3D space into a grid and projecting the LiDAR points onto the grid. Each cell in the grid contains information about the points that fall within it, such as the height, intensity, and other features.\n",
    "- Roughly the BEV computation can be broken down into the following steps:\n",
    "  - Filtering Points: filter out points outside the specified x, y, and z limits. \n",
    "  - Normalization: normalize the z-coordinates by subtracting the minimum z limit, which helps in handling different elevation levels correctly.\n",
    "  - Discretization: convert x and y coordinates to BEV map indices. The adjustment for y-coordinates to ensure there are no negative indices.\n",
    "  - Channel Computation: Then calculate channels for height, density, and intensity.\n",
    "  - Returned BEV Map is of 608x608x3 shape.\n",
    "\n"
   ],
   "id": "823e0bd58916211f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Performance metrics attained on the provided dataset.\n",
    "- The following metrics are performed for IOU threshold of 0.5.\n",
    "- We considered only the detections that were in the x range of 0 to 50 meters.\n",
    "- The following metrics are average score over all the frames in the dataset for the car class.\n",
    "\n",
    "\n",
    "`Precision: 0.6959`\n",
    "`Recall: 0.6724`\n",
    "`F1 Score: 0.6806`\n",
    "`Average IoU(Bounding box overlap): 0.4320`\n"
   ],
   "id": "8ceab1ba5f9345d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Instructions to run the code\n",
    "\n",
    " - git clone git@github.com:Harighs/Autonomous_vehicles_ue_2.git\n",
    " - cd Autonomous_vehicles_ue_2/SFA3D\n",
    " - pip install -r requirements.txt\n",
    " - cd sfa\n",
    " - we provide the bev_maps in .pkl file format which can be downloaded using the link https://drive.google.com/file/d/1QwRw2PNACQQQuhhbGUw3f2RoqwmRPS3c/view?usp=sharing \n",
    " - place the `bev_maps_v1.pkl` inside the `sfa` folder.\n",
    " - Now run the following command to evaluate the model on the provided dataset.\n",
    "   - python 3d_object_detection.py --data_path /path/to/bev_maps_v1.pkl --image_path /path/to/images \n",
    " - Set the --data_path to the path where the `bev_maps_v1.pkl` is placed and --image_path to the path where the waymo dataset are stored in the .pb format.\n",
    "  - When running the `3d_object_detection.py` file by default it will print out the performance metrics attained on the provided dataset.\n",
    "    - in case you want to visualize the detections on the images like BEV predictions or tracking for a each and every single frame you can comment out the several lines of code. Those instructions are provided in the `3d_object_detection.py` file.\n",
    " - We have also placed the prediction results for each frame in a video format placed it as `output.mp4`.\n",
    "                 \n"
   ],
   "id": "a019e5b02ef67d86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Contributions\n",
    "\n",
    "| Name                    | student ID | Task                                                                                             | \n",
    "|-------------------------|------------|--------------------------------------------------------------------------------------------------|\n",
    "| Ariharasudhan Muthusami | K52008888  | 3d object detection and evaluation, performance metrics(3d_object_detection.py), report writing. | \n",
    "| Harishankar Govindasamy | K11931161  |                                                                                                  | \n",
    "| Ayman Kamel             | K12136508  |                                                                                                  | \n",
    "| Jonathan Uyi Ehiosu     | K01628444  |                                                                                                  | \n",
    " \n"
   ],
   "id": "a6169c3edfa41dda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "44f9dd68430492c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
